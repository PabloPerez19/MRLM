---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{1.25cm}
- \usepackage{amsmath}
output: 
  pdf_document:
    number_sections: true
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: "es"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(knitr)
library(kableExtra)
library(GGally)
library(rsm)
library(car)

ggplot2::theme_set(ggplot2::theme_bw()) 
```

\input{titlepage}
\thispagestyle{empty}
\tableofcontents
\listoffigures
\listoftables

\newpage

\pagestyle{myheadings}
\setcounter{page}{1}

Se realizará una análisis de regresión lineal múltiple(RLM): 

$$y_i = \beta_0 + \beta_{1i} x_1 + \beta_2 x_{2i} + \cdots + \beta_k x_{ki} + \varepsilon_i, \ \varepsilon {\stackrel{iid} \sim} N(0, \sigma^2)$$

Con la intencion de validar si dicho modelo es adecuado para
```{r, echo = F}
data <- read.csv("AdmissionPredict.csv", sep=",", dec=".")
data <- data[1:100, -c(1,4,8)]
y <- select(data, Chance.of.Admit)
x <- select(data, -c(Chance.of.Admit))
```

\section{Base de datos}
\subsection{Breve Descripción de los Datos contextualizando el problema y explicando cada una de las variables involucradas en el modelo.}

La base de datos disponible en Kaggle corresponde a puntajes de admision creados para la predicción de las admisiones de posgrado en La India. 
Cuenta con 400 observaciones y 9 variables. De las cuales se consideran los primeros 100 estudiantes y 6 variables de interes por indicación de la docente.

|**Variables**|**Descripción**|
|-----------|-------------| 
|**Chance.of.Admit:**| Posibilidad de ser admitido.|
|**GRE Score:**      |Examen que tiene como finalidad medir la capacidad de razonamiento verbal, razonamiento cuantitativo, y habilidades para pensar y escribir de forma analítica.|
|**TOEFL Score:**    |Prueba estandarizada de dominio del idioma inglés.|
|**SOP:**            |Ensayo de admisión o solicitud de postgrado.|
|**LOR:**            |Carta de recomendación.|
|**CGPA:**           |Promedio general acumulado en el pregrado.| 

|**No se consideran**| **Descripción**|
|-----------|-------------| 
|**Serial No.**| Numero de serial que identifica a cada estudiante|
|**University Rating** | Calificación universitaria|
|**Research Experience**| Si tiene experiencia en investigación o no|

\section{Análisis descriptivo}
\subsection{Grafico de dispersión con Matriz de Correlaciones y conclusiones}

```{r, echo = F}
#Matriz de dispersión con histogramas en la diagonal
gg2<-ggpairs(data,upper=list(continuous = wrap("smooth",alpha = 0.3, size=1.2,method = "lm")),lower=list(continuous ="cor"))
for(i in 1:ncol(data)){
gg2[i,i]<-gg2[i,i]+
geom_histogram(breaks=hist(data[,i],breaks = "FD",plot=F)$breaks,
               colour = "red",fill="lightgoldenrod1")
}

gg2
```


\section{Modelo Ajustado de Regresion Lineal Multiple(MRLM)}
```{r, echo = F}
model = lm(data$Chance.of.Admit~., data)
summary(model) #¿ésto no debe incluirse?
```
\subsection{Tabla de parámetros ajustados}
```{r, echo = F}
tabla.coef <- summary(model)$coefficients 
row.names(tabla.coef) <- c("$\\beta_0$", "$\\beta_1$", "$\\beta_2$", "$\\beta_3$", "$\\beta_4$", "$\\beta_5$")
tabla.coef %>%
  kable(row.names = T, escape = F,
        col.names = c("Estimación", "Error estándar", "$T_0$", "Valor P"),
        align = "c", caption = "Resumen de los coeficientes", booktab = T, digits = 4) %>%
  kable_styling(latex_options = "HOLD_position")
```
\subsection{Ecuación Ajustada}
Con base en la tabla de parámetros estimados se obtiene la ecuación de regresión ajustada:


$$\widehat{Y}_i = \widehat{\beta}_0 + \widehat{\beta}_1X_{i1} + \widehat{\beta}_2X_{i2} + \cdots+ \widehat{\beta}_5X_{i5}, \quad i = 1, 2, \ldots, 100$$

$$\widehat{Y}_i = -1.7723 + 0.0041X_{i1} + 0.0029X_{i2} - 0.0120X_{i3} + 0.0428X_{i4} + 0.0757X_{i5}, \quad i = 1, 2, \ldots, 100$$

\subsection{Tabla Anova}
```{r, echo = F}
kable(anova(rsm(Chance.of.Admit~FO(GRE.Score,TOEFL.Score,SOP,LOR,CGPA), data = data)), caption = 'Tabla ANOVA para el modelo')
```
\subsection{Prueba de significancia del Modelo}
$$
\begin{cases}
\begin{aligned}
H_0&: \beta_1  = \cdots = \beta_5 = 0 \\
H_1&: \text{Al menos un } \beta_j \neq 0
\end{aligned}
\end{cases}
$$
\subsection{Coeficiente de determinación $R^2$: proporción de la variabilidad total de la respuesta explicada por el modelo y opiniones al respecto}
$$R^2 = \frac{\text{SSR}}{\text{SST}} = 1 - \frac{\text{SSE}}{\text{SST}}$$
$$R^2 = \frac{2.3674478}{2.3674478+0.6744272} = `r 2.3674478/(2.3674478+0.6744272)`$$

```{r, echo = F}
kable(summary(model)$r.squared, caption = "Multiple R-squared")
```

\section{Coeficientes de regresión estandarizados}
Calcule los coeficientes de regresión estandarizados y concluya acerca de cuál de las variables aporta máss a la respuesta según la magnitud en valor absoluto de tales coeficientes (cuidado, no confunda esto con la significancia de los coeficientes de regresión)

```{r, echo = F}
#CREANDO FUNCION PARA EXTRAER COEFICIENTES ESTIMADOS SUS IC DEL 95, VIF'S Y
#COEFICIENTES ESTANDARIZADOS
miscoeficientes <- function (modelo,datos){
  coefi <- coef (modelo)
  datos2 <- as.data.frame (scale(datos))
  coef.std=c(0, coef (lm(update (formula(modelo),~.+0),datos2)))
  limites=confint (modelo,level=0.95)
  vifs=c (0,vif (modelo))
  resul=data.frame (Estimación=coefi,Limites=limites,Vif=vifs,Coef.Std=coef.std)
  cat("Coeficientes estimados, sus I.C, Vifs y Coeficientes estimados estandarizados","\n")
  resul
}

#Obtencion de tabla de coeficientes
kable(miscoeficientes (model,data))
```


\section{Significancia individual de los parámetros del modelo}
Pruebe la significancia individual de cada uno de los parámetros del modelo (excepto intercepto), usando la prueba t. Establezca claramente la prueba de hipótesis y el criterio de decisión.
\subsection{Tabla de la significancia individual de los parámetros}
```{r, echo = F}
tabla.coef <- summary(model)$coefficients 
row.names(tabla.coef) <- c("$\\beta_0$", "$\\beta_1$", "$\\beta_2$", "$\\beta_3$", "$\\beta_4$", "$\\beta_5$")
tabla.coef %>%
  kable(row.names = T, escape = F,
        col.names = c("Estimación", "Error estándar", "$T_0$", "Valor P"),
        align = "c", caption = "Resumen de los coeficientes", booktab = T, digits = 4) %>%
  kable_styling(latex_options = "HOLD_position")
```
\subsection{Pruebas de hipotesis}

$$
\begin{cases}
\begin{aligned}
H_0&: \beta_1   = 0 \\
H_1&: \beta_1 \neq 0
\end{aligned}
\end{cases}
$$
$$
\begin{cases}
\begin{aligned}
H_0&: \beta_2   = 0 \\
H_1&: \beta_2 \neq 0
\end{aligned}
\end{cases}
$$
$$
\begin{cases}
\begin{aligned}
H_0&: \beta_3   = 0 \\
H_1&: \beta_3 \neq 0
\end{aligned}
\end{cases}
$$
$$
\begin{cases}
\begin{aligned}
H_0&: \beta_4   = 0 \\
H_1&: \beta_4 \neq 0
\end{aligned}
\end{cases}
$$
$$
\begin{cases}
\begin{aligned}
H_0&: \beta_5   = 0 \\
H_1&: \beta_5 \neq 0
\end{aligned}
\end{cases}
$$
\section{Ejercicio6}
Teniendo en cuenta los resultados anteriores, realice una prueba con sumas de cuadrados extras con test lineal general; especifique claramente el modelo reducido y completo, estadístico de la prueba, su distribución, cálculo de valor P, decisión y conclusión a la luz de los datos. Justifique la hipótesis que desea probar en este numeral.

\section{Ejercicio7}

Calcule las sumas de cuadrados tipo I (secuenciales) y tipo II (parciales) ¿Cuál de las variables tienen menor valor en tales sumas? ¿Qué puede significar ello?

\section{Residuales estudentizados vs. Valores ajustados}

Construya y analice gráficos de los residuales estudentizados vs. Valores ajustados y contra las variables de regresión utilizadas. ¿Qué información proporcionan estas gráficas?
\subsection{Gráfico de los residuales estudentizados vs. Valores ajustados}
Construya una gráfica de probabilidad normal para los residuales estudentizados. ¿Existen razones para dudar de la hipótesis de normalidad sobre los errores en este modelo?

```{r, echo = F}
residualPlots(model,tests=FALSE,type="rstudent",quadratic=FALSE,col=2,cex=1.5)
```

\section{Prueba de normalidad para los residuales estudentizados}
Construya una gráfica de probabilidad normal para los residuales estudentizados. ¿Existen razones para dudar de la hipótesis de normalidad sobre los errores en este modelo?
\subsection{Gráfico q-norm residuales estudentizados}
```{r, echo = F}
test=shapiro.test(rstudent(model))
qqnorm(rstudent(model),cex=2)
qqline(rstudent(model),col=2)
legend("topleft",legend=rbind(c("Statistic W","p.value"),round(c(test$statistic,test$p.value),digits=5)),cex=0.4)
```

\section{Diagnostico sobre la presencia de observaciones atipicas, de balanceo y/o influenciales y conclusiones}

```{r, echo = F}
influence.measures(model)
influence.measures(model)$is.inf
# influencias: 10-11-32-37-53-65-66-92
```

\section{Ejercicio11}

Ajuste el modelo de regresión sin las observaciones 10, 38 y 92, suponga que se establece que hay un error de digitación con estas dos observaciones, presente sólo la tabla de parámetros ajustados resultante ¿Cambian notoriamente las estimaciones de los parámetros, sus errores estándard y/o la signficancia? ¿Qué concluye al respecto? Evalúe el gráfico de normalidad para los residuales estudentizados para este ajuste ¿mejoró la normalidad?

Concluya sobre los efectos de este par de observaciones.

```{r, echo = F}
AdmissionPredict_sin_influencias <- data %>% slice(-c(10, 11, 32, 37, 53, 65, 66, 92)) 

modelo_sin_influencias <- lm(Chance.of.Admit~.,data = AdmissionPredict_sin_influencias)
anova(rsm(Chance.of.Admit~FO(GRE.Score,TOEFL.Score,SOP,LOR,CGPA), data = AdmissionPredict_sin_influencias))
summary(modelo_sin_influencias)

residualPlots(modelo_sin_influencias,tests=FALSE,type="rstudent",quadratic=FALSE,col=2,cex=1.5)

test_sin_influencias = shapiro.test(rstudent(modelo_sin_influencias)) #Test de normalidad sobre residuales estudentizados
qqnorm(rstudent(modelo_sin_influencias),cex=2)
qqline(rstudent(modelo_sin_influencias),col=2)
legend("topleft",legend=rbind(c("Statistic W","p.value"),round(c(test_sin_influencias$statistic,test_sin_influencias$p.value),digits=5)),cex=0.4)

```
\section{Ejercicio 12}

Para el modelo con todas las variables y sin las observaciones 10, 38 y 92, realice diagnósticos de multicolinealidad mediante
  
  \subsection{Matriz de correlación de las variables predictoras}
  \subsection{VIF's}
  \subsection{Proporciones de varianza}

```{r, echo = F}
#a.
cor(data)

#b.
vif(model)

#c.
#colldiag(model)

# sin observaciones de balanceo
#a.
cor(AdmissionPredict_sin_influencias)

#b.
vif(modelo_sin_influencias)

#c.
#colldiag(modelo_sin_influencias)
```

\section{Ejericio13}

En el modelo ajustado sin las observaciones 10, 38 y 92, construya modelos de regresión utilizando los métodos de selección (muestre de cada método sólo la tabla de resumen de este y la tabla ANOVA y la de parámetros estimados del modelo finalmente resultante):

  \subsection{Selección según el $R^2_{adj}$}
  \subsection{Selección según el estadístico $C_p$}
  \subsection{Stepwise}
  \subsection{Selección hacia adelante o forward}
  \subsection{Selección hacia atrás o backward}

\section{Selección del modelo}
Con base en los anteriores numerales, ¿Cuál modelo sugiere para la variable respuesta? ¿por qué?
